%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 


\documentclass[a4paper,12pt,twoside,openright]{report}


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Peter E.\ Conn\xspace}
\def\authorcollege{Trinity Hall\xspace}
\def\authoremail{pc424@cl.cam.ac.uk}
\def\dissertationtitle{A Safety Enhancing Source Translation for C}
\def\wordcount{xx,xxx}

\usepackage{url}
\usepackage{epstopdf}
\usepackage{epsfig,graphicx,parskip,setspace,tabularx,xspace} 
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{rotating}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{minted}
\usetikzlibrary{shapes, arrows}

%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\newpage
{\Huge \bf Abstract}
\vspace{24pt} 

Current research into the area of providing pointer safety to C programs suffers from a few systematic flaws.
First, the analysis performed by such systems is inextricably linked to the transformation required to provide pointer safety.
Second, they are studied in isolation and not in combination with commonly used compiler optimizations or as part of a widespread compiler tool chain.
Finally, the majority of these approaches sacrifice binary compatibility, requiring the entire libraries a program uses to be recompiled as well or even the program to be rewritten.

This dissertation aims to provide solutions to these problems.
It uses an approach where the analysis and transformation are kept separate, with a single analysis working with two drastically different transformations.
It investigates the effects of the two prevailing methods of ensuring pointer safety (fat pointers and lookup tables) on commonly used optimizations passes.
It provides methods for maintaining very high binary compatibility with programs that use already compiled libraries, and evaluates the costs of doing so.

Additionally, a taxonomy is created for classifying and evaluating current methods for providing pointer safety.
It goes beyond the currently quantitative measure of performance overhead imposed by a pointer safety system and includes qualitative measures including the types of safety provided, completeness and compatibility.
Finally an argument is made that such techniques tend to fall on a spectrum between providing 100\% safety and 100\% compatibility and places current techniques on that spectrum.

\newpage
\vspace*{\fill}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\onehalfspacing

%% START OF MAIN TEXT 

\chapter{Introduction}
\pagenumbering{arabic} 
\setcounter{page}{1} 

Pointer errors account for many bugs in C, ranging from simple off-by-one errors where the programmer writes one past the end of the array to malicious buffer overflow attacks, where an attacker inputs data designed to manipulate the code into writing past the end of the array and over some other important data.

C allows many practices that make such errors easy to make, for example a pointer can legally point one past the end of an array (although dereferencing it is undefined).
A pointer frequently starts pointing to its valid area of memory and then is modified (through pointer arithmetic) to point to an invalid area of memory.
This pointer is modified again, bringing it back to point to the valid area and used ,though used in practice, this is not allowed in the standard.
For example, Ghostscript, a freeware PostScript interface violates the standard by issuing pointers to the \verb!-1! element of stacks \cite{ghostscript}.

One method of dealing with such attacks is to keep track of data about the valid area of memory that a pointer has access to, and consult this data on pointer dereference.
In this dissertation, the data used to determine the validity of a pointer is the address of the start of the area of allocated memory (the base) and the address one past its end (the bound).
Furthermore, the base and bound data must be associated with the pointer in some way.

\begin{figure}
\centering
\tikzstyle{block} = [rectangle, draw, 
text width=5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{lib} = [rectangle, draw, fill=green!40, 
text width=5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{comp} = [rectangle, draw, fill=blue!40, 
text width=5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{line} = [draw, -latex']
\begin{tikzpicture}[node distance = 3cm, auto]
	\node [block] 						(code) 		{Source Code};
	\node [comp, right of=code] 		(ccured) 	{CCured-like Analysis};
	\node [comp, above of=ccured] 		(bandage) 	{Fat Pointer Transform};
	\node [block, right of=bandage] 	(exe1) 		{Bounds Checked Binary};
	\node [comp, below of=ccured] 		(softbound) {SoftBound-like Transform};
	\node [block, right of=softbound] 	(exe2) 		{Bounds Checked Binary};
	\node [lib, below right of=exe2]	(hash)		{HashTable};
	\node [lib, above right of=exe2]	(mem)		{MemTable};
	\path[line] (code) -- (ccured);
	\path[line] (ccured) -- (bandage);
	\path[line] (ccured) -- (softbound);
	\path[line] (code) -- (bandage);
	\path[line] (code) -- (softbound);
	\path[line] (bandage) -- (exe1);
	\path[line] (softbound) -- (exe2);
	\path[line] (mem) -- (exe2);
	\path[line] (hash) -- (exe2);
\end{tikzpicture}
\caption{Overview of Components of Bandage}
\label{fig:Components}
\end{figure}

Implemented for the purposes of this dissertation was the Bandage system, consisting of multiple parts as shown in Figure \ref{fig:Components}.
Bandage consists of three LLVM passes and two C libraries.
The two transformation LLVM passes implement different methods of associating data about pointers with the pointers themselves.
With fat pointers, pointers themselves are replaced by structures that contain the pointer value and their bounds information.
With a lookup table approach, the address of the pointer is used as the key to a lookup table containing the bounds information.
The two C libraries contain different implementations of the lookup table.

The CCured-like analysis is used to identify the many pointers not modified using pointer arithmetic during the life of the program, and can be used by the transformation passes to prevent bounds checking there.

The implementation of Bandage is the first example of the separation of analysis and transformation and serves as a good example of its benefits.
By having the CCured-like analysis being an independent LLVM pass is can be combined with different transformations to achieve different trade-offs in terms of safety, runtime and binary compatibility, allowing a much larger range of potential solutions to a specific need.

The two different transformation passes are used to investigate the interplay with common optimisation passes - to determine which optimization passes do the most to mitigate the overhead generated by them and which passes they impede.

The entire Bandage system is designed to provide high binary compatibility by drawing a boundary around the source files it can transform and ensuring that the instrumentation is stripped when it passes through this boundary.
This allows programs using Bandage to also use libraries that haven't been modified, but also restricts the safety completeness it can offer, as pointers that come in through this boundary do not contain sufficient information for full safety.

Finally, Bandage will be used as the primary example in the classification of pointer safety systems, providing a reference point to compare other systems with and a in depth study to highlight some subtleties in the taxonomy.

This dissertation continues with brief coverage of the background information required: the types of pointer safety, examples of vulnerabilities caused by lack of it and an overview of how pointers are dealt with in LLVM IR.
A related work section follows, enumerating previous efforts to provide pointer safety, drawing together common themes between them and highlighting the position of this work.

The design and implementation section contains details of the two transformation passes (the fat pointer and the metadata) and the one analysis pass (the CCured-like analysis).
The evaluation section covers the runtime penalties, tested on handcrafted microbenchmarks and the olden benchmark suite, alongside performance security focussed correctness tests.
Everything is wrapped up in the conclusion and a few example source programs are annotated in the appendices to give a concrete view of the transformations performed.

\chapter{Background} 
\input{Background/Background}

\chapter{Related Work} 
\input{RelatedWork/RelatedWork}

\chapter{Design and Implementation} 
\input{Implementation/Implementation}

\chapter{Evaluation} 
\input{Evaluation/Evaluation}

\chapter{Summary and Conclusions} 

The novel idea of separation of analysis and implementation was developed and implemented paving the way for a reusable ecosystem of components to enforce pointer safety and to identify where it needs to be enforced.

The two prevalent methods of carrying spatial pointer information and tracking its safety were implemented and their effects on commonly used compiler optimizations was investigated.
\textbf{It was found that...}

By placing the existing pointer safety systems in a common evaluation framework they can be compared and contrasted, allowing the users to make a choice of which system to use or allowing researchers to identify gaps in the design space for future work.
This evaluation also identified a core trade-off in this area, that of compatibility vs completeness, with Cyclone taking its place at the completeness end of the spectrum and Heapmon taking its place at the compatibility end.

\section{Software Engineering Practices}

The use of a strong test suite was invaluable during the implementation, and the only thing I would change if I did this again would be making it even stronger.

In terms of implementation costs, implementing Bandage took considerably more effort and was far more bug prone than implementing SoftBound.
This is in large part due to Bandage changing the representation of pointers - making the change from raw pointers to fat pointers required a considerable amount of code to be written in one piece - if the entire change did not work, the source programs would break.
In the SoftBound implementation however, the implementation could be broken down into small pieces (eg providing bounds for local variables, then passing them through functions), and at each stage the source programs would compile, though the checking may not be complete.

Although this does provide a nice guarantee with Bandage that if the program compiles, bounds checking is more likely to be thorough, it creates an all-or-nothing situation in the presence of cases that haven't been implemented where Bandage either breaks the code or performs well, while Softbound can provide bounds checking for that that has been implemented.

Unexpected setbacks were discovered in trying to run the Softbound transformation on the Raspberry Pi, as both uthash and memtables required modification to run on 32-bit systems.

\appendix
\singlespacing

\bibliographystyle{plain} 
\bibliography{Bibliography} 

\end{document}
