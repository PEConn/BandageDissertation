During this chapter, types will be referred to in LLVM notation.
An \verb!i32! stands for a 32-bit integer, a \verb!i8! stands for an 8 bit integer (or char) and a pointer to a type is denoted by the type followed by an asterisk.

\section{Working with pointers in LLVM IR}

In LLVM IR, space on the stack is set aside with the \verb!alloca! instruction, which returns a pointer to the allocated memory.
Therefore the line \verb!int a! in C is converted into \verb!%a = alloca i32! in LLVM IR.
It should be noted that the variable \verb!%a! is actually the type of \verb!i32*!.
This means that in the declaration \verb!int *a! will create in LLVM IR the variable \verb!%a! of type \verb!i32**!.

The \verb!store! instruction takes a piece of data and a pointer and stores the data in the area pointed to.
The following C code turns into the following LLVM code:

\begin{verbatim}
int a;
int b;
a = b;
\end{verbatim}

\begin{verbatim}
%a = alloca i32
%b = alloca i32
%1 = load i32* %b
store i32 %1, i32 %a
\end{verbatim}

Here, spaces on the stack for the variables \verb!a! and \verb!b! are created, and pointers to these spaces are stored in the variables \verb!%a! and \verb!%b! respectively.
The value stored in the area pointed to by \verb!%b! is loaded, and then stored in the area pointed to by the variable \verb!%a!.

\begin{verbatim}
int *c;
int d;
...
*c = d;
\end{verbatim}

\begin{verbatim}
%c = alloca i32*
%d = alloca i32
...
%1 = load i32** %c
%2 = load i32* %d
store i32 %2, i32* %c
\end{verbatim}

Here, in the C code we are assigning the value held in \verb!d! to the memory location pointed to by \verb!c! (assume that \verb!c! is set to a valid memory address during the \verb!...! otherwise the code results in undefined behaviour).

In LLVM IR, the variable \verb!%c! is created with type \verb!i32**! and the variable \verb!%d! is created with type \verb!i32*!.
The value stored in the memory pointed to by \verb!%c! is loaded into \verb!%1!, so \verb!%1! now contains the address pointed to by \verb!c! in the C code.
The value stored in the memory pointed to by \verb!%d! is loaded into \verb!%2! (the value contained within \verb!d! in the C code).
Finally the memory pointed to by \verb!%1! is set to the value contained in \verb!%2!.

The last interesting instruction for working with pointers is the GEP instruction.
GEP stands for 'Get Element Pointer', and is used for performing pointer arithmetic (it itself does not peform and memory access).

\begin{verbatim}
int *a, *b, *d;
int c;
a = b + 3;
c = d[3];
\end{verbatim}

\begin{verbatim}
%a = alloca i32*
%b = alloca i32*
%c = alloca i32
%d = alloca i32*

%1 = load i32** %b
%2 = getelementptr %1, i32 0, i32 3
store i32* %2, %a

%3 = load i32** %d
%4 = getelementptr %3, i32 0, i32 3
%5 = load i32* %4
store i32 %5, %c
\end{verbatim}

\verb!%1! contains the value of \verb!b! and the getelementptr is used for the pointer arithmetic.
The variable \verb!%1! is of type \verb!i32*!.
The second parameter of the GEP specifies how many of the size of the type of the first parameter we want to add.
In this case, and in most cases it is zero, saying that we don't want to add any of \verb!sizeof(i32*)! to the first parameter.
The third parameter specifies how many of the size of the type of the value contained within the first parameter we want to add, and in this case, we want to add \verb!3 * sizeof(i32)!.
Therefore the GEP returns:

\begin{verbatim}
%2 = %1 + 0 * sizeof(i32*) + 3 * sizeof(i32)
\end{verbatim}

This address is then stored in the memory pointed to by \verb!%a!.

The second operation can be rewritten as \verb!c = *(d + 3)!, so starts the same as the previous operation, except once the address of \verb!d+3! has been calculated, it is dereferenced to get the value contained there.

\section{Fat Pointers}
While a pointer contains an address to an area in memory, a fat pointer contains an address and additional information.
As implemented in Bandage, fat pointers contain three pointers, a value, a base and a bound.

\begin{verbatim}
int *x = malloc(5*sizeof(int));
x += 3;
\end{verbatim}

In bandage, the variable x, of type \verb!i32*! would be turned into a structure of type \verb!{i32*, i32*, i32*}!.
Assuming that malloc returned the address \verb!0x1000!, the variable x would contain \verb!{0x1000, 0x1000, 0x1020}! because it contains a pointer that currently points to \verb!0x1000! and whose valid addresses start at \verb!0x1000! inclusive and end at \verb!0x1020! not inclusive.
After the \verb!x += 3! instruction, the variable x would contain \verb!{0x1012, 0x1000, 0x1020}!.

In order to keep type safety in the LLVM IR, different types of pointers create different types of fat pointers, eg a \verb!i32*! creates an \verb!{i32*, i32*, i32*}! whereas a \verb!i8*! creates a \verb!{i8*, i8*, i8*}!.
This will result in a fat pointer class for every pointer type in the program, but because class information does not propagate to the final binary, this shouldn't create any space overhead.

However, this adds some complexity when pointers are cast to different types.
Previously, casting from a pointer to a pointer (for example casting from the \verb!i8*! returned from \verb!malloc! to the \verb!i32*! for the integer pointer in the above example would take one bitcast instruction with raw pointers.
With fat pointers, a new fat pointer would need to be created, the address of each field would need to be calculated, each field would have to be loaded, bitcast and then stored in the new fat pointer, adding a fair amount of overhead.
The current implementation is optimized for this case (detecting whether the result of a \verb!malloc! is going to be bitcast, and if so doesn't create the intermediate fat pointer).
\textbf{It may be worthwhile seeing how well this optimization does}.

\subsection{Types of Fat Pointer}

During the running of the program, each fat pointer can be classified as one of three types: \textit{HasBounds}, \textit{NoBounds} and \textit{Null}.

The \textit{Null} fat pointers have their value set to \verb!NULL!, and no restrictions on their base or bound.
They represent null pointers and throw an error whenever they are dereferenced.

The \textit{NoBounds} fat pointers have their base set to \verb!NULL! and not-\verb!NULL! in their value.
They represent fat pointers whose bounds we do not know, for example the result of a external function call.
These pointers cannot be bounds checked on dereference, so do not throw an error.

Finally, textit{HasBounds} pointers have not-\verb!NULL! in all of their fields and represent a pointer whose bounds we know.
These pointers are bounds checked on dereference and throw an error if the value is out of bounds.

\subsection{Pointers}

\subsubsection{Allocation}

The first step in the pointer transformation is to find all \verb!alloca! instructions that create a pointer, and replace them with a fat pointer.
Even at this early stage we can add some safety to the program by initialising the fat pointer value to be null.

In terms of performance, we are swapping one allocation instruction allocating a pointer's worth of memory with another, allocating three pointers worth of memory. 
On testing this was found to produce no performance difference, though could increase cache pressure (as the number of pointers that can fit on the cache are divided by three).

When the value was set to \verb!NULL!, an overhead of 1.7\% was added.

\subsubsection{Instruction-based vs Chain-based}

The original implementation of bandage moved through the program and transformed it on an instruction-by-instruction basis, gathering all information from the transformation from the instruction being transformed (eg the opcode, its arguments, the types of the arguments and the instruction type).

It was found that this approach, though originally simple, rapidly gained complexity as more sophisticated transformations were needed.
Upon integration with the CCured-like pointer analysis, the implementation was switched to a different, more holistic approach, that of instruction-chains.

An instruction chain is a sequence of instructions, where every instruction is used by the subsequent instruction.
Under this implementation, the source is searched for allocation instructions and call instructions - the two instructions that start instruction chains, and their usage was followed.

These instruction chains tend to terminate in one of a few common instructions:

\begin{itemize}
\item \textbf{Store} - A store instruction usually terminates two instruction chains, that of the pointer and that of the value.
\item \textbf{Call} - A call instruction terminates the instruction chains of all of the parameters that are used in it. Additionally it creates a new instruction chain of its return value (if that return value is used).
\item \textbf{Return} - Terminates the instruction chain of the return value.
\item \textbf{Compare} - Similar to a store instruction, this terminates the two instruction chains of its operands.
\end{itemize}

The following diagram shows the two use chains generated by the following code:

\begin{verbatim}
int *a;
int *b;
*a = *b;
\end{verbatim}
\tikzstyle{block} = [rectangle, draw, fill=blue!40, 
    text width=5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{line} = [draw, -latex']
\begin{tikzpicture}[node distance = 1.5cm, auto]
	\node [block] (a) {a = alloca};
	\node [block, below of=a] (load_a1) {load};
	\node [block, below of=load_a1, fill=yellow!60] (store) {store};
	\node [block, left of=a, node distance=3cm] (b) {b = alloca};
	\node [block, below of=b] (load_b1) {load};
	\node [block, below of=load_b1] (load_b2) {load};
	\path [line] (a) -- (load_a1);
	\path [line] (load_a1) -- (store);
	\path [line] (b) -- (load_b1);
	\path [line] (load_b1) -- (load_b2);
	\path [line] (load_b2) -- (store);
\end{tikzpicture}

\subsubsection{Loads}

Loads are where most of the work occurs with fat pointers.

First it must be determined whether the load needs be transformed to return the value contained within the fat pointer, or whether the load needs to return the fat pointer.
The latter case may arise when the load is to be used as the value in a store (where we store the fat pointer in anther fat pointer) or when the load is loading the parameter for a function call.
Checking for these cases is an example where the chain-based view of the data allows simpler checks than the instruction-based view.

If it is determined that the value of the fat pointer must be loaded instead of the fat pointer itself, bounds checking can occur.
The value, base and bounds values are loaded out of the fat pointer and have arithmetic performed on them.
If the value is less than the base, or greater than or equal to the base, a user defined function is called.

The transformation for the code derefencing the variable \verb!a! is shown below, with the raw pointer code being:

\begin{verbatim}
%1 = load i32** %a
\end{verbatim}

Which will be transformed into:

\begin{verbatim}
%value_addr = getelementptr %FatPointer* %FP.a, i32 0, i32 0
%value = load i32** %base_addr
%base_addr = getelementptr %FatPointer* %FP.a, i32 0, i32 1
%base = load i32** %base_addr
%bound_addr = getelementptr %FatPointer* %FP.a, i32 0, i32 2
%bound = load i32** %base_addr
call void @BoundsCheck(i32* value, i32* base, i32* bound)
%1 = load %value
\end{verbatim}

The \verb!getelementptr! instructions get the addresses of the fields of the fat pointer.
Though the Bandage implementation creates three new \verb!getelementptr! instructions on every dereference, these offsets are constant, and so repeated calls should be removed further down the compilation pipeline.

The cost of fat pointer dereference comes from the additional loads, and the bounds checking.

If bounds checking were ignored, overhead would be introduced because on dereference there are now two loads instead of just one - there is one to get the pointer out of the fat pointer, and one to dereference the pointer.
\textbf{This would be a nice place for a microbenchmark on the raspberry pi}

\subsubsection{Geps}

\subsection{Functions}

Functions are duplicated into a function with a modified signature, such that every parameter is replaced by the fat pointer version of that parameter (so a pointer is replaced by a fat pointer, a struct is replaced by a version of the struct that uses fat pointers).

A map from original functions to fat pointer capable functions is kept, and when a call instruction is encountered, the call target is updated to the fat pointer version of the function if it exists.

If no such fat pointer version exists, there may need to be some conversion code around the call.
This code will strip any fat pointers that are passed as parameters into raw pointers and, if the function returns a raw pointer, will wrap this into a fat pointer.
This, newly created fat pointer will have its base set to \verb!NULL!, making it a \textit{NoBounds} pointer described above.

\subsubsection{Multiple Source File Projects}

Since LLVM module passes run on a single *.c source file, issues arise when using functions declared in other source files that the user has still written.
When Bandage encounters a function definition but no declaration, it assumes that the function is external to the project, and is not to be modified.
This works well for cases where the included function is part of a library that the programmer cannot modify, such as \verb!malloc! or \verb!printf!, however also is triggered when the function declaration is in another *.c file that the programmer can modify.

Therefore, an additional pass was created, the \textbf{Function List} pass.
This pass, takes a single llvm IR file and a filename and outputs all of the functions declared in that IR file.

Now, the process for using Bandage is as follows:
\begin{itemize}
\item Run the \textbf{Function List} pass over all source files, appending to the same function list file.
\item Run the \textbf{Bandage} pass over all source files, with the function list file as a parameter.
\end{itemize}

This gives the Module pass information about other modules that it would not normally have access to, and allows it to distinguish between function definitions for functions the programmer has no control over (so they can be ignored) and function definitions the programmer has control over.

On finding a function definition that matches a function in the function list file, Bandage transforms the function definition.
This function definition will be identically transformed to the function declaration in the file it is declared in, and so the linker will be able to merge them together after the Bandage transformation is complete.

Additionally, the functions added by Bandage (the null check and the bounds check) are defined in all files it modifies, but only declared in the file if the main function is present.

\subsubsection{malloc}

When a \verb!malloc! instruction is encountered, the fat pointer being assigned to has its value and base set to the return value, and its bound set to the base plus the argument to the malloc instruction (the size of the area of memory to be allocated).

\subsubsection{free}
When a \verb!free! instruction is encountered, the argument is followed backwards to find the fat pointer it came from.
The value of the fat pointer is set to \verb!NULL!.
\subsubsection{Evaluate String Function}

\subsection{Structs}

First, it is nessecary to isolate the structs that can be modified - those that are defined and used only in the code that Bandage can modify.
For example, Bandage should be able to recognise that \verb!FILE! struct, included from \verb!stdio.h! should not be modified.

To accomplish this, Bandage collects all of the structs used in the input file, and subtracts from this set those structs that are used in functions (as a parameter or return type) that are declared, but not defined.
So for example, \verb!FILE! would originally be flagged for modification, but upon discovery of the function declaration for \verb!fopen!, it would be removed from the list.
In order to play nicely with projects that consist of multiple source files, the function file used to determine which functions can be modified is used again.

Once the safe to modify structs are isolated, two modifications must be carried out on them:

\begin{itemize}
\item Pointers within the struct must be modified to fat pointers of the same object.
\item Structs within the struct must be changed to structs that themselves are modified.
This includes correctly modifying self-referential structs, such as a linked list.
\end{itemize}

The latter point is made simple due to an upgrade to the LLVM type system introduced in LLVM 3.0, type completion.
This allows a type to be specified with no body, be used and have its body filled in later.

Therefore the algorithm to create the fat pointer types consists of:

\begin{itemize}
\item Collect a set of all struct.
\item Subtract those structs that are used in functions that are defined externally.
\item Create an empty type, for each struct in the set.
\item For each struct in the set:
\begin{itemize}
\item For each element in the struct construct a new element with a type such that:
\begin{itemize}
\item For every layer of pointer indirection, there is now a fat pointer.
\item For every nesting of static arrays, there is a static array of the same dimension, but potentially of a new type.
\item If the base type is a struct which is in the set, change it to the (potentially empty) fat pointer capable struct.
\end{itemize}
\item Fill the previously empty type.
\end{itemize}
\end{itemize}

In this way, all structs can be modified in any plain linear order without having to worry about which structs reference other structs.
	
\subsubsection{Sizeof Woes}

The Bandage pass works on LLVM IR an intermediate stage created by the clang compiler.
Unfortunately the clang compiler replaces instances of the \verb!sizeof! operator with constant integers in this process.

The fat pointer versions of structs will always be equal to or larger in size than their raw counter parts, as pointers take up three times their previous size.
This leads to the undesirable situation where the source program allocates an area of memory for a struct using the common \verb!MyStruct *S = malloc(sizeof(MyStruct))! idiom.
The LLVM IR will contain a constant integer (indistinguishable from other all other constant integers) representing the size of the original struct, though the actual struct used will be the fat pointer version, which requires more memory.
This can lead to memory access violations.

\section{The Bounds Check Function}

\section{Lookup Table - Softbound}

For comparison between a fat pointer and meta-data approaches, the SoftBound system was implemented.
SoftBound was chosen because, apart from differences in where the bounds information is stored, it is very similar to the fat pointer approach as it associates each pointer with a base and bound.

\subsection{Pointers on the Stack}

The SoftBound approach for local pointers with only one layer of indirection is very simple, two additional pointers are created alongside the original one to hold the base and the bound.

\begin{verbatim}
// Before
int *ptr;
// After
int *ptr;
int *ptr_base;
int *ptr_bound;
\end{verbatim}

This is essentially the same as the fat pointer approach, except the data is stored as multiple variables instead of all in one structure.
However, whereas replacing all uses of the pointer with a fat pointer then requires modifications in its further uses, this approach breaks nothing further down the line.

This is implemented by iterating through all instructions in the program and acting on \verb!alloca!s of pointer types.
On finding such an \verb!alloca!, two new pointers of the same type are created, and references of them are stored in a map, indexed by the reference of the original, such that further uses of the original pointer can be used to find its associated variables.

\subsection{Pointers on the Heap}

With the fat pointer approach, when a pointer is allocated on the heap its base and bounds are allocated alongside it, in the fat pointer structure.
SoftBound uses a table data structure to map the address of a pointer in memory to the base and bound for that pointer.

The base and bound are retrieved from the lookup table, indexed by the address of the pointer on every load.
For example, consider the case shown below, where each box contains the name of a variable, if it is local or its address if it is not, and its value below it. 

\noindent
\tikzstyle{pointer} = [rectangle, draw, 
    text width=5em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex']
\begin{tikzpicture}[node distance = 3cm, auto]
	\node [pointer] (a) {a \\ 0x1000};
	\node [pointer, right of=a] (b) {0x1000 \\ 0x5000};
	\node [pointer, right of=b] (c) {0x5000 \\ 0x3000};
	\node [pointer, right of=c] (d) {0x3000 \\ 42};
	\path [line] (a) -- (b);
	\path [line] (b) -- (c);
	\path [line] (c) -- (d);
\end{tikzpicture}

The local variable \verb!a! points to the address \verb!0x1000!, which points to the address \verb!0x5000! which points to the address \verb!0x3000! which contains \verb!42!. This would be accompanied by the following lookup table:

\noindent
\begin{tabular}{|r|r|r|}
\hline Address & Base & Bound \\
\hline 0x1000 & 0x5000 & 0x5008 \\
\hline 0x5000 & 0x3000 & 0x3004 \\
\hline
\end{tabular}

Consider the following code:

\begin{verbatim}
***a=12;
\end{verbatim}

The first dereference is simple and requires no lookup as \verb!a! is a local variable and therefore has other local variables associated with it containing its base and bound.
The second dereference, loading the value from the pointer stored at \verb!0x1000!, is accompanied by a table lookup using the address of the pointer.
This lookup finds the base and bounds and performs the bounds check.

The third and final dereference follows the same pattern, loading the value at \verb!0x3000! from the pointer which it itself stored at \verb!0x5000!, using the address of the pointer (\verb!0x5000!) as a key to the lookup table and getting the correct bounds.

\subsubsection{Table lookup}

This table lookup is performed whenever a pointer stored on the heap is dereferenced, and this is what introduces the major disadvantage of the lookup table approach.
Such a table must map from the address of the pointer to the base and bounds of that pointer.

Bandage was created with an exchangable backend, to allow multiple table implementations.
The source program can load one of multiple provided headers to implement different types of lookup table, and the correct functions are called for table setup, teardown, lookup and storage.

Three different implementations of lookup table were implemented to compare the trdae-off between size and lookup cost.

\subsubsection{Toy lookup table}

The first implementation is a toy example, consisting of a constant sized array that stores bounds that it is given and is linearly searched for lookup.
If an attempt is made to add an entry to a filled table, the 'not-most-recently-used' entry is overwritten.

This table was partially created for debugging purposes, but also to examine the idea of imperfect bounds storing.
Since most programs will have incomplete bounds information from calls to external functions (such as \verb!gets!), the ideal of 100\% bounds coverage is practically not achievable.
Therefore it is interesting to investigate the performance advantage gained from relaxing the constraint that all internally that all internally declared pointers must have their bounds fully tracked.

\subsubsection{Hash Table}

The lookup table was implemented using \verb!uthash!, a hash table implementation written in C and released under the BSD revised license. 

A hash table uses a hashing function to split its contents into a series of buckets, each of which contains a list of elements.
On access, the index is hashed to find the correct bucket and the contents of the bucket are scanned linearly to find the correct item.
In order for this scan to run in constant time, the number of items in the bucket must be bounded.

In \verb!uthash!, the limit of items in each bucket is set to \verb!10!, and once this is exceeded, the number of buckets is doubled and items are redistributed into new buckets.
This means that lookup time has a constant bound (though it still a linear lookup, which would take longer than an array access), though adding items to the hash table can either be constant time, or can cause the buckets to be resized, an operation linear in the size of the hash table.

The advantage of a hash table is that it is quite small, with its size depending on the number of entries it contains.

\subsubsection{Memtable}

In contrast to the hash table is \verb!memtable!, which maps from areas of memory.
It essentially creates a linear array of entries, with each entry covering a range of addresses.
Since we are mapping from a single pointer to a pair of pointers, each area of memory mapped from is 8 bytes to 16 bytes.
The size of the table is very large, as it consumes space for every field that it could contain, however value lookup consists only of pointer arithmetic and derefence so is contant time, as is value insertion.
However, the size of the table means it cannot be entirely contained within the cache, so variable access times may arise due to cache effects.

Current implementations of x86-64 do not allow programs to use the full range of addresses available to them, so for a pointer of 8 bytes/ 64 bits, only the least significant 48 bits will be used in address translation.
Additionally, the last 16 bits are a sign extension of the 62nd bit, resulting in addresses falling into two categories, those that begin with 16 '1's and those that begin with 16 '0's.

The upper set of these addresses (those starting with '1') are used by the kernel on most operating systems, with the lower half being used by the application.
Therefore, the memory table only needs to be able to deal with the lower set - a range of addresses extending from $0$ to $2^{47}$.

However, the memtable needs to be contained within this address space as well, with a ratio of 2 bytes of storage required for every 1 byte the table is capable of mapping.
To keep the arithmetic tidy, the available memory was partitioned into 4, with 3 quarters being devoted to the table and 1 quarter being used for application memory.

Finally, this application memory needs to have available space at both the top and the bottom.
This is because the text and initialized data read from the program file are stored at the bottom of the available address space, and the stack and the heap are store at the top end of the address space.

\textbf{This will have a diagram with it.} Therefore, of the $2^{47}$ available addresses the program can have, $2^{45}$ is still used for the program, whereas $3\times 2^{45}$ are used for the memtable.
The $3\times 2^{45}$ area allocated for the table is positioned at offset $2^{44}$, effectively bisecting the application memory into that used for text and that used for the stack and heap.

Therefore, to find the bounds information associated with the pointer $x$:

\begin{itemize}
\item If $x$ is greater than $2^{44}$ (it is in the heap and stack region), subtract $3\times 2^{45}$.
\item Divide the address by $8$ (the entry coverage).
\item Multiply the address by $16$ (the entry size).
\item Add the table start offset $2^{44}$.
\end{itemize}

One of the primary aims of this scheme was to keep implementation simple, and its purpose was to provide a comparison for runtimes.
Multiple improvements could be made.
Firstly, the table could be shrunk to 2/3 of the available space, not 3/4.
Secondly, a split of 50:50 between the text and stack and heap segments of memory may not be ideal.

The idea of some sort of compression for the bounds information was considered, for example storing the base and bound as 32-bit offsets from the value of the pointer instead of 64-bit absolute offsets, however this would require a table update on each piece of pointer arithmetic and would go against the design of SoftBound.
\subsection{Functions}

Since pointers are copied in function calls, the address of the pointer cannot be used to carry information about the pointer's base and bound across the function boundary.
Therefore, locally defined functions are modified so that their base and bound are passed in explicitly as additional parameters.

As with the fat pointer approach, this required duplicating all provided functions to those with modified signatures.
Special care must be taken because there is no longer a one-to-one mapping between the parameters in the original function and those in the modified function.

\begin{verbatim}
// Before
int Func(int *x);
// After
int Func(int *x, int *x_base, int *x_bound);
\end{verbatim}

Additionally, the base and bounds of the return value must be transferred across the function call boundary.
This involves creating a structure that contains the pointer value, base and bound and returning this instead.

There are two key differences between this returned structure and a fat pointer.
The first is in the purpose, a fat pointer will be returned from a function and then used as a fat pointer.
The return structure will be returned from the function and immediately have its information stripped from it into local variables, it is purely a vehicle for returning multiple values.

The second is in how these structures deal with nested pointers.
A multi-level pointer, when transformed into a fat pointer, has each layer of indirection turned into a structure, eg:

\begin{verbatim}
// Before
int **a;
// After
struct FatPointer.1{int *value, *base, *bound;};
struct FatPointer.2{struct FatPointer.2 *value, *base, *bound;};
struct FatPointer.2 a;
\end{verbatim}

This is because a multi-level fat pointer must contain all of the bounds information with it.
On the other hand, with SoftBound we only care about the pointer we are passing, so:

\begin{verbatim}
// Before
int **a;
// After
struct ReturnPointer{int **value, **base, **bound};
struct ReturnPointer a;
\end{verbatim}

We only need the bounds of the immediate pointer since the bounds of anything that it points to will be stored in the lookup table.

In terms of implementation, the duplicated functions returned the 'pointer return' object and code was added at each call site to extract the value, base and bound and to associate the value with the base and bound.

\section{Setting pointer bounds}

The two most common actions that cause a change in pointer bounds are detailed in the functions section above - \verb!malloc! and \verb!free!.
For the former, the base and bound of the set pointer are set to the return value and the return value plus the parameter respectively.
For the latter, the value is set to null.

The following sections cover the other common situations in which bounds information for a pointer is changed.

\subsection{Setting to constant string}

LLVM IR displays a distinct pattern for the following code:

\begin{verbatim}
char *username="george";
\end{verbatim}

The constant string is stored in the file text section as a \verb!private unnamed_addr constant [Y x i8]! (where \verb!Y! is the length of the string, including null terminator).
The assignment is a \verb!store! instruction with the value being a GEP operator (which is different from a GEP instruction) to the start of the memory allocated to the string.

Since setting to a constant string is a static operation - the string and its length are known at compile time, setting the bounds is also a static operation.
Bandage detects the type of the string (the constant-sized character array) and sets the bound equal to the base plus the size.

\subsection{Setting to the address}

\begin{verbatim}
int b;
int *a=&b;
\end{verbatim}

For this situation a more general, run-time method is used to detemine the size of the r-value.
A GEP is created to the type of the r-value, with its first operand being a null pointer (so the address calculation starts at the offset zero), and with its other operand specifying the second object of that type.

This causes a calcuation, starting from offset zero, calculating the address of the second object of that type in a non-existant array.
This will return the size of the r-value.
As before, on non-ARM processors the GEP will be be reduced to a constant in further stages of compilation.

\subsection{Setting to another pointer}

Setting a pointer equal to another pointer is simple, the bounds information of the r-value is set to that of the l-value, as is the value of the pointer.
Occasionally, pointer casts may be need to be inserted for typing (as the bounds are typed equal to the pointer, so if the pointer is cast, so must the bounds).

\subsection{Setting to pointer arithmetic}

The bounds information is modified as above, though this time the value of the r-value fat pointer has arithmetic performed on it (in the form of GEP instructions) before being stored in the value of the l-value fat pointer.

At this point, no bounds checks are performed, it is perfectly legal for a pointer to have arithmetic performed on it that leads it to go out of bounds and later to have further arithmetic that brings it back into bounds.

\subsection{Setting to NULL}

Finally, pointers are frequently set to be equal to the null constant.
In this case, the bounds information is not changed, only the value.
The reason for this being that a null pointer is flagged by bounds checking before the bounds information is touched and therefore two additional assignments would add unessecary overhead.

\section{CCured Analysis}

%\section{Not-Null Analysis}
%
%Whereas the previous analysis is concerned with spatial safety (overrunning the end of the valid space allocated to a pointer), Cyclone's Not-Null analysis is concerned with temporal safety.
%
%In the CCured analysis, \textit{SAFE} pointers are allowed to be null, and a null check is still inserted before dereference.
%As an optimisation, a simplified form of not-null analysis was implemented, in order to remove some of the redundant null checks.
%
%\subsubsection{Manual Null Checks}
%
%Frequently the programmer will check for null themselves, such as this example from the olden benchmark \verb!TreeAdd!:
%
%\begin{verbatim}
%int TreeAdd(tree_t *t){
%  if(t == NULL)
%    return 0;
%  int leftval = TreeAdd(t->left);
%  int rightval = TreeAdd(t->right);
%  int value = t->val;
%  return leftval + rightval + value;
%}
%\end{verbatim}
%
%Here, obviously adding manual null checks to the dereferences of \verb!t! would be pointless.
%
%Bandage searches for compare instructions, comparing pointers to null, and follows them to check for a jump instruction.
%If a jump instruction is found, the basic block jumped to on a successful null check (where the pointer is not null) is marked as not requiring null checks for that pointer.
%The pointer, if not \textit{SAFE} will still undergo bounds checks.

\section{Arrays}

C provides no safety for constant size arrays.
For completeness, both the Bandage and SoftBound passes implement bounds checking on array access.

This is made almost trivial because the type system carries the bounds of arrays, and therefore in the transformation pass the array access can be modified by looking at the type of the pointer operand to the GEP instruction (used to calculate the address of the requested array entry).
